# (å¯çœç•¥) !pip install -q pandas requests python-dateutil tqdm

import os, time, warnings, requests, pandas as pd
from datetime import date, timedelta
from dateutil.relativedelta import relativedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import OrderedDict
from functools import lru_cache
from typing import Dict, Tuple, Optional, List
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
import streamlit as st

try:
    from tqdm import tqdm
except ImportError:
    tqdm = None  # æ²’è£å°±ä¸é¡¯ç¤ºé€²åº¦æ¢

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# ========= åŸºæœ¬è¨­å®š =========
API_KEY = os.getenv("POLYGON_API_KEY", "J_wZYB3rGZBaFv2tdyg21X1vmVXrMW21").strip()
assert API_KEY and all(ord(c) < 128 for c in API_KEY), "API_KEY ç„¡æ•ˆæˆ–å«é ASCII"
BASE = "https://api.polygon.io"

TARGET_YEAR = date.today().year - 1     # å¹´åº¦å°æ¯”ï¼šå»å¹´çš„ Q4
MAX_WORKERS = 16

# ========= HTTP Sessionï¼ˆé€£ç·šæ±  + é‡è©¦ï¼‰=========
SESSION = requests.Session()
retries = Retry(total=2, backoff_factor=0.3, status_forcelist=[429, 500, 502, 503, 504])
adapter = HTTPAdapter(pool_connections=128, pool_maxsize=128, max_retries=retries)
SESSION.mount("https://", adapter); SESSION.mount("http://", adapter)

# å¥æª¢
r = SESSION.get(f"{BASE}/v3/reference/tickers", params={"limit":1,"apiKey":API_KEY}, timeout=15)
r.raise_for_status()
print(f"âœ… Polygon API OK | TARGET_YEAR={TARGET_YEAR}")

# ========= é€šç”¨å·¥å…· =========
def _get(url, params=None, retry=2, sleep=0.25):
    params = dict(params or {}); params["apiKey"] = API_KEY
    last = None
    for _ in range(retry+1):
        try:
            r = SESSION.get(url, params=params, timeout=30)
            r.raise_for_status()
            js = r.json()
            if isinstance(js, dict) and js.get("status") == "ERROR":
                raise RuntimeError(js.get("error") or "Polygon API error")
            return js
        except Exception as e:
            last = e; time.sleep(sleep)
    raise last

def _paged(url, params=None):
    params = dict(params or {}); params["apiKey"] = API_KEY
    out = []
    r = SESSION.get(url, params=params, timeout=30); r.raise_for_status()
    js = r.json()
    if isinstance(js, dict) and js.get("status") == "ERROR":
        raise RuntimeError(js.get("error") or "Polygon API error")
    out += js.get("results", []) or []
    while js.get("next_url"):
        nxt = js["next_url"]; base = nxt.split("?")[0]
        qs = nxt.split("?")[1] if "?" in nxt else ""; p2={}
        for kv in qs.split("&"):
            if not kv or kv.startswith("apiKey="): continue
            k, v = kv.split("=", 1); p2[k] = v
        p2["apiKey"] = API_KEY
        r = SESSION.get(base, params=p2, timeout=30); r.raise_for_status()
        js = r.json()
        if isinstance(js, dict) and js.get("status") == "ERROR":
            raise RuntimeError(js.get("error") or "Polygon API error")
        out += js.get("results", []) or []
    return out

def _to_date(s):
    try: return pd.to_datetime(s).date()
    except: return None

# ========= åƒè€ƒèˆ‡åŸºæœ¬è³‡æ–™ =========
@lru_cache(maxsize=1_000)
def fetch_all_us_common():
    url = f"{BASE}/v3/reference/tickers"
    params={"market":"stocks","type":"CS","active":"true","locale":"us","limit":1000,"sort":"ticker"}
    out=[]
    while True:
        js=_get(url,params); out += [x["ticker"] for x in js.get("results",[]) if x.get("ticker")]
        nxt=js.get("next_url")
        if not nxt: break
        url=nxt.split("?")[0]
        params={kv.split("=")[0]:kv.split("=")[1] for kv in nxt.split("?")[1].split("&") if not kv.startswith("apiKey=")}
    return out

@lru_cache(maxsize=10_000)
def get_ref(ticker):
    return _get(f"{BASE}/v3/reference/tickers/{ticker}").get("results",{}) or {}

def classify_mc(market_cap):
    try:
        if market_cap is None: return None
        mc = float(market_cap)
        if not (mc > 0): return None
    except Exception:
        return None
    B = 1_000_000_000; M = 1_000_000
    if mc >= 200*B: return "Mega"
    if mc >= 10*B:  return "Large"
    if mc >= 2*B:   return "Mid"
    if mc >= 300*M: return "Small"
    if mc >= 50*M:  return "Micro"
    return "Nano"

# === å‰ä¸€äº¤æ˜“æ—¥æ—¥æœŸ ===
def _most_recent_mkt_day():
    return (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")

# === åªå–æ˜¨æ”¶ï¼ˆèˆŠç‰ˆç›¸å®¹ä¿ç•™ï¼‰===
@lru_cache(maxsize=2)
def prev_close_map_for_all(group_day: str | None = None):
    day = group_day or _most_recent_mkt_day()
    url = f"{BASE}/v2/aggs/grouped/locale/us/market/stocks/{day}"
    js = _get(url, {"adjusted": "true"})
    mp = {}
    for r in js.get("results", []) or []:
        t = r.get("T") or r.get("ticker")
        c = r.get("c")
        if t and c is not None:
            mp[t] = float(c)
    return mp

# === æ–°å¢ï¼šæ˜¨æ”¶ + æˆäº¤é‡ï¼ˆåŒæ™‚å¿«å–ï¼‰===
@lru_cache(maxsize=2)
def daily_agg_map_for_all(group_day: str | None = None):
    """
    å›å‚³ {ticker: {"c": close, "v": volume}}ï¼Œè³‡æ–™ç‚ºä¸Šä¸€äº¤æ˜“æ—¥ (adjusted)
    """
    day = group_day or _most_recent_mkt_day()
    url = f"{BASE}/v2/aggs/grouped/locale/us/market/stocks/{day}"
    js = _get(url, {"adjusted": "true"})
    mp = {}
    for r in js.get("results", []) or []:
        t = r.get("T") or r.get("ticker")
        if not t:
            continue
        c = r.get("c"); v = r.get("v")
        mp[t] = {
            "c": (float(c) if c is not None else None),
            "v": (float(v) if v is not None else None),
        }
    return mp

def last_close_fast(ticker, mp=None):
    if mp and ticker in mp:
        val = mp[ticker]
        if isinstance(val, dict):
            c = val.get("c")
            return (float(c) if c is not None else None)
        return val  # å…¼å®¹èˆŠç‰ˆ map: ç›´æ¥æ˜¯ close å€¼
    js = _get(f"{BASE}/v2/aggs/ticker/{ticker}/prev")
    arr = js.get("results", [])
    return (arr[0]["c"] if arr else None)

@lru_cache(maxsize=50_000)
def polygon_avg_volume_last_n_days(ticker: str, ndays: int = 10) -> Optional[float]:
    """
    å›å‚³éå» ndays å…§ï¼ˆæœ€å¤š ndays å€‹äº¤æ˜“æ—¥ï¼‰çš„å¹³å‡æ—¥æˆäº¤é‡ã€‚
    æœƒå¤šæŠ“å¹¾å¤©ä»¥é¿é–‹é€±æœ« / å‡æ—¥ã€‚
    """
    end = date.today() - timedelta(days=1)
    start = end - timedelta(days=ndays * 2)  # å¤šæŠ“é¿å…é€±æœ«
    start_str = start.strftime("%Y-%m-%d")
    end_str   = end.strftime("%Y-%m-%d")

    url = f"{BASE}/v2/aggs/ticker/{ticker}/range/1/day/{start_str}/{end_str}"
    js = _get(url, {"adjusted": "true", "sort": "desc", "limit": ndays})
    arr = js.get("results", []) or []
    vols = [r.get("v") for r in arr if r.get("v") is not None]

    if not vols:
        return None
    return float(sum(vols) / len(vols))

# ========= Balance Sheetsï¼ˆå­£å ±ï¼‰=========
def _pick_fin_value(obj, path_flat, path_nested):
    if path_flat in obj and obj[path_flat] is not None:
        try: return float(obj[path_flat])
        except: pass
    cur = obj
    try:
        for k in path_nested: cur = cur.get(k, {})
        if cur is not None: return float(cur)
    except: pass
    return None

def _pick_date(obj):
    for k in ("period_end","period_of_report_date","end_date","fiscal_period_end_date","reporting_date"):
        if obj.get(k):
            d = _to_date(obj[k]);
            if d: return d
    return None

@lru_cache(maxsize=50_000)
def polygon_bs_quarterly_map(ticker: str) -> Dict[Tuple[int,int], Dict[str, Optional[float]]]:
    url  = f"{BASE}/stocks/financials/v1/balance-sheets"
    fy_gte = date.today().year - 3
    rows = _paged(url, {
        "tickers": ticker, "timeframe": "quarterly",
        "fiscal_year.gte": fy_gte, "limit": 2000, "sort": "period_end.asc"
    })
    out = {}
    for r in rows:
        tk_list = r.get("tickers") or []
        if tk_list and ticker not in tk_list: continue
        y = r.get("fiscal_year"); q = r.get("fiscal_quarter")
        if not y or not q: continue
        dt = _pick_date(r)
        eq = _pick_fin_value(r, "total_equity", ["financials","balance_sheet","total_equity","value"])
        db = _pick_fin_value(r, "long_term_debt_and_capital_lease_obligations",
                                ["financials","balance_sheet","long_term_debt_and_capital_lease_obligations","value"])
        out[(int(y), int(q))] = {"total_equity": eq, "long_term_debt_and_capital_lease_obligations": db, "label_date": dt}
    return out

def polygon_bs_annual_q4(ticker: str, years: Tuple[int,int]) -> Dict[int, Tuple[Optional[float], Optional[float]]]:
    mp  = polygon_bs_quarterly_map(ticker)
    out = {}
    for y in years:
        v = mp.get((y,4)); out[y] = (v.get("total_equity"), v.get("long_term_debt_and_capital_lease_obligations")) if v else (None, None)
    return out

def polygon_bs_latest_quarter(ticker: str) -> Tuple[Optional[str], Optional[float], Optional[float]]:
    mp = polygon_bs_quarterly_map(ticker)
    if not mp: return (None, None, None)
    y,q = sorted(mp.keys())[-1]; v = mp[(y,q)]
    lab = f"{y}Q{q}"
    return (lab, v.get("total_equity"), v.get("long_term_debt_and_capital_lease_obligations"))

# ========= Ratiosï¼ˆå– P/E èˆ‡ EPS_TTMï¼‰=========
@lru_cache(maxsize=50_000)
def polygon_ratios_latest_pe_and_eps(ticker: str) -> tuple[Optional[float], Optional[float]]:
    """
    å›å‚³ (PE, EPS_TTM)ã€‚è‹¥ PE ç¼ºï¼Œå°±ç”¨ Price/EPS_TTM å›æ¨ã€‚
    """
    url  = f"{BASE}/stocks/financials/v1/ratios"
    rows = _paged(url, {"tickers": ticker, "order": "desc", "limit": 20})
    pe = eps_ttm = None
    for r in rows:
        ok = False
        if isinstance(r.get("tickers"), list): ok = (ticker in r["tickers"])
        elif isinstance(r.get("ticker"), str): ok = (r["ticker"] == ticker)
        else: ok = True
        if not ok:
            continue
        eps_ttm = _pick_fin_value(r, "earnings_per_share", ["financials","ratios","earnings_per_share","value"])
        pe      = _pick_fin_value(r, "price_to_earnings", ["financials","ratios","price_to_earnings","value"])
        break

    # è‹¥ PE ç¼ºä¸” EPS_TTM æœ‰ï¼Œç”¨æ˜¨æ”¶åƒ¹å›æ¨
    if (pe is None or pe <= 0) and eps_ttm not in (None, 0):
        px = last_close_fast(ticker)
        if px:
            try: pe = float(px) / float(eps_ttm)
            except: pass

    try: pe = float(pe) if pe is not None else None
    except: pe = None
    try: eps_ttm = float(eps_ttm) if eps_ttm is not None else None
    except: eps_ttm = None
    return pe, eps_ttm

# ========= å¤šå£å¾‘ã€Œæ·¨åˆ©ã€æŠ½å–ï¼ˆä¾› YoY èˆ‡ TTM è¨ˆç®—ï¼‰=========
def _pick_net_income_any(r) -> Optional[float]:
    CANDS = [
        ("net_income", ["financials","income_statement","net_income","value"]),
        ("net_income_loss", ["financials","income_statement","net_income_loss","value"]),
        ("net_income_loss_attributable_common_shareholders",
         ["financials","income_statement","net_income_loss_attributable_common_shareholders","value"]),
        ("net_income_loss_available_to_common_stockholders_basic",
         ["financials","income_statement","net_income_loss_available_to_common_stockholders_basic","value"]),
        ("consolidated_net_income_loss",
         ["financials","income_statement","consolidated_net_income_loss","value"]),
        ("profit_loss", ["financials","income_statement","profit_loss","value"]),
    ]
    for flat, nested in CANDS:
        try:
            if r.get(flat) is not None:
                return float(r.get(flat))
        except:
            pass
        v = _pick_fin_value(r, flat, nested)
        if v is not None:
            try: return float(v)
            except: pass
    return None

@lru_cache(maxsize=50_000)
def polygon_net_income_last_annual_and_quarterly(ticker: str) -> Tuple[Optional[float], Optional[float]]:
    """
    å›å‚³ (net_income_lastyear, net_income_lastQ)
    - lastyear: æœ€æ–°ä¸€å€‹å¹´åº¦ï¼ˆannualï¼‰çš„æ·¨åˆ©
    - lastQ   : æœ€æ–°ä¸€å€‹å­£åº¦ï¼ˆquarterlyï¼‰çš„æ·¨åˆ©
    """
    url  = f"{BASE}/stocks/financials/v1/income-statements"

    # ---- å¹´åº¦ï¼šæ‰¾æœ€æ–°ä¸€å¹´çš„æ·¨åˆ© ----
    rows_y = _paged(url, {
        "tickers": ticker, "timeframe": "annual",
        "fiscal_year.gte": date.today().year - 6,
        "limit": 2000, "sort": "period_end.asc"
    })
    annual = []
    for r in rows_y:
        tks = r.get("tickers") or []
        if tks and ticker not in tks:
            continue
        pe = _to_date(r.get("period_end")) or date(r.get("fiscal_year") or 1900, 12, 31)
        ni = _pick_net_income_any(r)
        if ni is not None:
            annual.append((pe, float(ni)))
    annual.sort(key=lambda x: x[0])
    net_income_lastyear = annual[-1][1] if annual else None

    # ---- å­£åº¦ï¼šæ‰¾æœ€æ–°ä¸€å­£çš„æ·¨åˆ© ----
    rows_q = _paged(url, {
        "tickers": ticker, "timeframe": "quarterly",
        "fiscal_year.gte": date.today().year - 3,
        "limit": 2000, "sort": "period_end.asc"
    })
    quarterly = []
    for r in rows_q:
        tks = r.get("tickers") or []
        if tks and ticker not in tks:
            continue
        pe = _to_date(r.get("period_end")) or date(r.get("fiscal_year") or 1900, 12, 31)
        ni = _pick_net_income_any(r)
        if ni is not None:
            quarterly.append((pe, float(ni)))
    quarterly.sort(key=lambda x: x[0])
    net_income_lastQ = quarterly[-1][1] if quarterly else None

    return net_income_lastyear, net_income_lastQ

@lru_cache(maxsize=50_000)
def polygon_net_income_growth_yoy_pct(ticker: str) -> Optional[float]:
    """
    å›å‚³ç™¾åˆ†æ¯”ï¼ˆå¦‚ 5% -> 5.0ï¼‰ã€‚
    å…ˆå˜—è©¦å¹´åº¦ YoYï¼›è‹¥ä¸è¡Œå†ç”¨ TTM YoYï¼ˆæœ€è¿‘4å­£ vs å‰4å­£ï¼‰ã€‚
    """
    url  = f"{BASE}/stocks/financials/v1/income-statements"

    # ---- A) å¹´åº¦ YoY ----
    rows_y = _paged(url, {
        "tickers": ticker, "timeframe": "annual",
        "fiscal_year.gte": date.today().year - 6,
        "limit": 2000, "sort": "period_end.asc"
    })
    annual = []
    for r in rows_y:
        tks = r.get("tickers") or []
        if tks and ticker not in tks:
            continue
        pe = _to_date(r.get("period_end")) or date(r.get("fiscal_year") or 1900, 12, 31)
        ni = _pick_net_income_any(r)
        if ni is not None:
            annual.append((pe, float(ni)))
    annual.sort(key=lambda x: x[0])

    if len(annual) >= 2:
        prev_ni = annual[-2][1]
        last_ni = annual[-1][1]
        if prev_ni is not None and prev_ni > 0:
            try:
                return float(((last_ni - prev_ni) / abs(prev_ni)) * 100.0)
            except:
                pass  # è½åˆ° TTM å˜—è©¦

    # ---- B) TTM YoYï¼ˆè¿‘8å­£ï¼‰----
    rows_q = _paged(url, {
        "tickers": ticker, "timeframe": "quarterly",
        "fiscal_year.gte": date.today().year - 3,
        "limit": 2000, "sort": "period_end.asc"
    })
    qvals = []
    for r in rows_q:
        tks = r.get("tickers") or []
        if tks and ticker not in tks:
            continue
        ni = _pick_net_income_any(r)
        if ni is not None:
            qvals.append(float(ni))
    if len(qvals) >= 8:
        last4 = sum(qvals[-4:])
        prev4 = sum(qvals[-8:-4])
        if prev4 > 0:
            try:
                return float(((last4 - prev4) / abs(prev4)) * 100.0)
            except:
                return None
    return None

# ========= æŠ€è¡“æŒ‡æ¨™ï¼šMACDï¼ˆä¾æ–‡ä»¶ï¼‰ & EMA =========
@lru_cache(maxsize=50_000)
def polygon_macd_latest_n(
    ticker: str,
    n: int = 2,
    *,
    timespan: str = "day",
    short_window: int = 12,
    long_window: int = 26,
    signal_window: int = 9,
    series_type: str = "close",
    order: str = "desc",
    expand_underlying: bool | str = False,
    timestamp: str | None = None,
) -> List[Dict]:
    params = {
        "timespan": timespan,
        "adjusted": "true",
        "short_window": short_window,
        "long_window": long_window,
        "signal_window": signal_window,
        "series_type": series_type,
        "order": order,
        "limit": max(1, min(5000, int(n))),
    }
    if expand_underlying:
        params["expand_underlying"] = "true"
    if timestamp:
        params["timestamp"] = timestamp

    js = _get(f"{BASE}/v1/indicators/macd/{ticker}", params)
    vals = (js.get("results", {}) or {}).get("values", []) or []

    out: List[Dict] = []
    for v in vals:
        try:
            out.append({
                "timestamp": int(v.get("timestamp")),
                "value": float(v.get("value")),
                "signal": float(v.get("signal")),
                "histogram": float(v.get("histogram")),
            })
        except Exception:
            continue
    return out

def macd_cross_flags_from_latest2(items: List[Dict]) -> Dict[str, bool]:
    EPS = 1e-12
    if len(items) < 2:
        return {k: False for k in [
            "above_zero","below_zero","golden_cross","death_cross","zero_cross_up","zero_cross_down"
        ]}
    cur, prev = items[0], items[1]
    m_now, s_now = cur["value"], cur["signal"]
    m_pre, s_pre = prev["value"], prev["signal"]
    h_now, h_pre = (m_now - s_now), (m_pre - s_pre)

    return {
        "above_zero": (m_now > 0 + EPS),
        "below_zero": (m_now < 0 - EPS),
        "golden_cross": (h_pre <= 0 + EPS) and (h_now > 0 + EPS),
        "death_cross":  (h_pre >= 0 - EPS) and (h_now < 0 - EPS),
        "zero_cross_up":   (m_pre <= 0 + EPS) and (m_now > 0 + EPS),
        "zero_cross_down": (m_pre >= 0 - EPS) and (m_now < 0 - EPS),
    }

@lru_cache(maxsize=50_000)
def polygon_ema_latest_value(ticker: str, window=200, timespan="day"):
    js = _get(f"{BASE}/v1/indicators/ema/{ticker}", {
        "timespan": timespan, "window": window, "series_type": "close",
        "adjusted": "true", "order": "desc", "limit": 1
    })
    vals = (js.get("results", {}) or {}).get("values", []) or []
    try:
        return float(vals[0]["value"])
    except:
        return None

# ========= Equity / Debt é›™æ——æ¨™ =========
def equity_debt_flags_dual_polygon(ticker: str):
    y1, y2 = TARGET_YEAR, TARGET_YEAR - 1
    ann = polygon_bs_annual_q4(ticker, years=(y2, y1))
    eq_y2, db_y2 = ann.get(y2, (None, None))
    eq_y1, db_y1 = ann.get(y1, (None, None))
    _, eq_q, db_q = polygon_bs_latest_quarter(ticker)

    eq_up = (
        "Y" if (eq_y1 is not None and eq_y2 is not None and eq_q is not None
                and (eq_y1 > eq_y2) and (eq_q > eq_y1)) else "N"
    )
    db_down = (
        "Y" if (db_y1 is not None and db_y2 is not None and db_q is not None
                and (db_y1 < db_y2) and (db_q < db_y1)) else "N"
    )
    return eq_up, db_down

# ========= å–®æª”è’é›† =========
def collect_all_inputs_for_debug(ticker, PREV=None):
    row = OrderedDict()
    row["Symbol"] = ticker

    ref = get_ref(ticker) or {}
    row["Company"]  = ref.get("name")
    row["Sector"]   = ref.get("sic_sector")
    row["Industry"] = ref.get("sic_description")
    row["Market Cap"] = ref.get("market_cap")
    row["Market Cap Class"] = classify_mc(ref.get("market_cap"))

    # Priceï¼ˆæ˜¨æ”¶ï¼‰
    px = last_close_fast(ticker, PREV)
    row["Price"] = round(px, 4) if px else None

    # æ˜¨æ—¥æˆäº¤é‡ï¼ˆèˆ‡ Price åŒä¸€å¤©ï¼‰
    vol = None
    if PREV and ticker in PREV and isinstance(PREV[ticker], dict):
        vol = PREV[ticker].get("v")
    row["Volume (Prev Day)"] = (int(vol) if isinstance(vol, (int, float)) and vol == int(vol)
                                else (float(vol) if vol is not None else None))

    # æ–°å¢ï¼šéå» 10 å¤©å¹³å‡æˆäº¤é‡
    avg_vol_10d = polygon_avg_volume_last_n_days(ticker, ndays=10)
    row["AvgVolume_10D"] = (round(avg_vol_10d, 2) if avg_vol_10d is not None else None)

    # å¹´å ±/å­£å ±ï¼ˆbalance sheetsï¼‰
    y1, y2 = TARGET_YEAR, TARGET_YEAR-1
    ann = polygon_bs_annual_q4(ticker, years=(y2, y1))
    eq_y2 = db_y2 = eq_y1 = db_y1 = None
    if y2 in ann: eq_y2, db_y2 = ann[y2]
    if y1 in ann: eq_y1, db_y1 = ann[y1]
    row[f"Equity_{y2}"] = eq_y2; row[f"Debt_{y2}"] = db_y2
    row[f"Equity_{y1}"] = eq_y1; row[f"Debt_{y1}"] = db_y1

    qlab, eq_q, db_q = polygon_bs_latest_quarter(ticker)
    row["Latest Quarter Label"] = qlab
    row["Equity_LatestQ"] = eq_q; row["Debt_LatestQ"] = db_q

    row["Annual_Equity_Up(y1>y2)"] = (eq_y1 is not None and eq_y2 is not None and eq_y1 > eq_y2)
    row["Annual_Debt_Down(y1<y2)"] = (db_y1 is not None and db_y2 is not None and db_y1 < db_y2)
    row["Q_vs_Y1_Equity_Up"]       = (eq_q is not None and eq_y1 is not None and eq_q > eq_y1)
    row["Q_vs_Y1_Debt_Down"]       = (db_q is not None and db_y1 is not None and db_q < db_y1)

    # Equity / Debt ç¨ç«‹æ——æ¨™
    eq_up, db_down = equity_debt_flags_dual_polygon(ticker)
    row["Equity Up"] = eq_up
    row["Debt Down"] = db_down

    # ä¼°å€¼ï¼šP/Eã€EPS (TTM)ã€Net Income YoY Growthï¼ˆ%ï¼‰ã€PE/G
    pe, eps_ttm = polygon_ratios_latest_pe_and_eps(ticker)
    row["P/E"] = pe
    row["EPS (TTM)"] = (round(eps_ttm, 6) if eps_ttm is not None else None)

    growth_pct = polygon_net_income_growth_yoy_pct(ticker)
    row["NetIncome YoY Growth (%)"] = (round(growth_pct, 4) if growth_pct is not None else None)
    row["PE/G"] = (round(pe / growth_pct, 4) if (pe is not None and growth_pct not in (None, 0)) else None)

    # æ–°å¢ï¼šæ·¨åˆ©æ°´æº–ï¼ˆå¹´åº¦ / å­£åº¦ï¼‰ï¼‹æ˜¯å¦ > 0
    ni_lastyear, ni_lastQ = polygon_net_income_last_annual_and_quarterly(ticker)
    row["net_income_lastyear"] = (round(ni_lastyear, 2) if ni_lastyear is not None else None)
    row["net_income_lastQ"] = (round(ni_lastQ, 2) if ni_lastQ is not None else None)
    row["net_income_lastyear>0?"] = (ni_lastyear is not None and ni_lastyear > 0)
    row["net_income_lastQ>0?"] = (ni_lastQ is not None and ni_lastQ > 0)

    # MACDï¼ˆä¾æ–‡ä»¶åƒæ•¸ï¼‰
    macd_items = polygon_macd_latest_n(
        ticker, n=2,
        timespan="day", short_window=12, long_window=26, signal_window=9,
        series_type="close", order="desc", expand_underlying=False
    )
    if macd_items:
        row["MACD (12,26,9)"] = macd_items[0]["value"]
        row["MACD_Signal"]    = macd_items[0]["signal"]
        row["MACD_Hist"]      = macd_items[0]["histogram"]
    else:
        row["MACD (12,26,9)"] = None
        row["MACD_Signal"]    = None
        row["MACD_Hist"]      = None

    flags = macd_cross_flags_from_latest2(macd_items)
    row["MACD_AboveZero"] = flags["above_zero"]
    row["MACD_BelowZero"] = flags["below_zero"]
    row["ZeroCross_Up"]   = flags["zero_cross_up"]
    row["ZeroCross_Down"] = flags["zero_cross_down"]
    row["GoldenCross"]    = flags["golden_cross"]
    row["DeathCross"]     = flags["death_cross"]

    # EMA200 èˆ‡åƒ¹æ ¼ä½ç½®
    ema200 = polygon_ema_latest_value(ticker, window=200, timespan="day")
    row["EMA200"]         = ema200
    row["Price>EMA200"]   = (row.get("Price") is not None and ema200 is not None and row["Price"] > ema200)
    row["Price<EMA200"]   = (row.get("Price") is not None and ema200 is not None and row["Price"] < ema200)
    row["Trend_EMA200"]   = ("Up" if row["Price>EMA200"] else ("Down" if row["Price<EMA200"] else None))

    # äº¤æ˜“ç‹€æ…‹ï¼ˆä½ çš„è¦å‰‡ï¼‰
    buy  = (row["GoldenCross"] and row["MACD_BelowZero"] and row["Price>EMA200"])
    sell = (row["DeathCross"]  and row["MACD_AboveZero"] and row["Price<EMA200"])
    row["Status"] = ("BUY" if buy else ("SELL" if sell else "HOLD"))

    return row

def process_one_with_reason_and_inputs_v2(ticker, PREV=None):
    return collect_all_inputs_for_debug(ticker, PREV=PREV)

# ========= å…¨å¸‚å ´æƒæï¼ˆå«é€²åº¦æ¢ï¼‰=========
def run_full_market_inputs_with_reason(outfile="full_market_inputs_with_reason.csv",
                                       part_every=1500, max_workers=MAX_WORKERS,
                                       skip_share_classes=True, 
                                       limit: int | None = None): # <-- æ–°å¢ limit åƒæ•¸

    # æ•´å€‹æµç¨‹ä½¿ç”¨ st.status åŒ…è£ï¼Œå–ä»£åŸæœ‰çš„é ‚éƒ¨ print()
    with st.status("ğŸš€ Starting full market scan...", expanded=True) as status:
        st.write("Fetching stock list...") # <-- å–ä»£ print()

        syms = fetch_all_us_common()
        if skip_share_classes:
            syms = [s for s in syms if not any(s.endswith(f".{c}") for c in list("ABCDEFGHIJKLMNOPQRSTUVWXYZ"))]
        
        # æ‡‰ç”¨ limit åƒæ•¸ (ç”± 11251.py å‚³å…¥ï¼Œä¾‹å¦‚ 10)
        if limit is not None and limit > 0:
            syms = syms[:limit]

        PREV = daily_agg_map_for_all()  # æ‰¹æ¬¡æ˜¨æ”¶ + æˆäº¤é‡
        total = len(syms)
        st.write(f"âœ… Got {total} tickers to process | MAX_WORKERS = {max_workers}") # <-- å–ä»£ print()

        rows = []
        t0 = time.time()
        
        # æ›¿æ› tqdmï¼šå»ºç«‹ st.progress
        progress = st.progress(0, text="Starting scan...")
        processed = 0

        with ThreadPoolExecutor(max_workers=max_workers) as ex:
            futs = {ex.submit(process_one_with_reason_and_inputs_v2, s, PREV): s for s in syms}
            for i, f in enumerate(as_completed(futs), 1):
                s = futs[f]
                try:
                    r = f.result()
                    if r: rows.append(r)
                except Exception as e:
                    st.write(f"[WARN] {s} error: {e}") # <-- å–ä»£ print()

                # æ›¿æ› tqdm.update(1) çš„é‚è¼¯
                processed = i
                pct = int((processed / total) * 100)
                progress.progress(pct, text=f"Processed {processed}/{total} tickers ({pct}%)")

                if part_every and i % part_every == 0:
                    df_part = pd.DataFrame(rows)
                    path = f"{outfile}.part_{i}.csv"
                    df_part.to_csv(path, index=False, encoding="utf-8")
                    st.write(f"ğŸ’¾ partial saved: {path} (rows={len(df_part)})") # <-- å–ä»£ print()

        # ç§»é™¤åŸæœ‰çš„ if bar: bar.close()

        st.write("Saving full CSV...")
        df = pd.DataFrame(rows)
        try:
            df.to_csv(outfile, index=False, encoding="utf-8")
            st.write(f"âœ… saved full CSV: {outfile} | rows={len(df)}") # <-- å–ä»£ print()
        except Exception as e:
            st.write(f"[ERROR] save full CSV: {e}") # <-- å–ä»£ print()

        elapsed_min = (time.time() - t0) / 60
        st.write(f"â±ï¸ Total elapsed time: {elapsed_min:.1f} minutes")
        
        # æœ€çµ‚æ›´æ–°ç‹€æ…‹
        progress.progress(100, text="âœ… Completed all tasks")
        status.update(label="âœ… Full market scan completed successfully!", state="complete")

    return df
# ----------------------------------------------------------------------
# å·²ç§»é™¤åº•éƒ¨æ‰€æœ‰è‡ªå‹•åŸ·è¡Œï¼ˆæ¸¬è©¦å’Œå…¨å¸‚å ´åŸ·è¡Œï¼‰çš„ç¨‹å¼ç¢¼ï¼Œç¢ºä¿ä½œç‚ºæ¨¡çµ„è¼‰å…¥æ™‚ä¸æœƒè‡ªå‹•åŸ·è¡Œã€‚
# ----------------------------------------------------------------------
